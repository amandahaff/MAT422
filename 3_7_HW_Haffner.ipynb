{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMawWvE7gvQp4fozZdd3awX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amandahaff/MAT422/blob/main/3_7_HW_Haffner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.7 Neural Networks##"
      ],
      "metadata": {
        "id": "uUUZKJEjG_hk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Artificial neural networks is a collection of connected layers of units or nodes\n",
        "to loosely model the neurons in a biological brain. In this section, we illustrate the use of differentiation for training artificial neural networks to minimize cost functions.\n"
      ],
      "metadata": {
        "id": "CfsVdB8CHE7j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ0IRWx3GtJ7",
        "outputId": "ee5fb988-1dfc-4552-de0b-420e34b14703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dot product is: 2.1672\n",
            "The dot product is: 2.1672\n",
            "The dot product is: 4.1259999999999994\n",
            "The prediction result is: [0.7985731]\n",
            "The prediction result is: [0.87101915]\n",
            "Prediction: [0.87101915]; Error: [0.75867436]\n",
            "The derivative is [1.7420383]\n",
            "Prediction: [0.01496248]; Error: [0.00022388]\n"
          ]
        }
      ],
      "source": [
        "input_vector = [1.72, 1.23]\n",
        "weights_1 = [1.26, 0]\n",
        "weights_2 = [2.17, 0.32]\n",
        "\n",
        "# Computing the dot product of input_vector and weights_1\n",
        "first_indexes_mult = input_vector[0] * weights_1[0]\n",
        "second_indexes_mult = input_vector[1] * weights_1[1]\n",
        "dot_product_1 = first_indexes_mult + second_indexes_mult\n",
        "print(f\"The dot product is: {dot_product_1}\")\n",
        "\n",
        "import numpy as np\n",
        "dot_product_1 = np.dot(input_vector, weights_1)\n",
        "print(f\"The dot product is: {dot_product_1}\")\n",
        "\n",
        "dot_product_2 = np.dot(input_vector, weights_2)\n",
        "print(f\"The dot product is: {dot_product_2}\")\n",
        "\n",
        "# Wrapping the vectors in NumPy arrays\n",
        "input_vector = np.array([1.66, 1.56])\n",
        "weights_1 = np.array([1.45, -0.66])\n",
        "bias = np.array([0.0])\n",
        "\n",
        "def sigmoid(x):\n",
        "     return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def make_prediction(input_vector, weights, bias):\n",
        "     layer_1 = np.dot(input_vector, weights) + bias\n",
        "     layer_2 = sigmoid(layer_1)\n",
        "     return layer_2\n",
        "\n",
        "prediction = make_prediction(input_vector, weights_1, bias)\n",
        "print(f\"The prediction result is: {prediction}\")\n",
        "\n",
        "# Changing the value of input_vector\n",
        "input_vector = np.array([2, 1.5])\n",
        "prediction = make_prediction(input_vector, weights_1, bias)\n",
        "print(f\"The prediction result is: {prediction}\")\n",
        "\n",
        "target = 0\n",
        "mse = np.square(prediction - target)\n",
        "print(f\"Prediction: {prediction}; Error: {mse}\")\n",
        "\n",
        "derivative = 2 * (prediction - target)\n",
        "print(f\"The derivative is {derivative}\")\n",
        "\n",
        "# Updating the weights\n",
        "weights_1 = weights_1 - derivative\n",
        "prediction = make_prediction(input_vector, weights_1, bias)\n",
        "error = (prediction - target) ** 2\n",
        "print(f\"Prediction: {prediction}; Error: {error}\")"
      ]
    }
  ]
}